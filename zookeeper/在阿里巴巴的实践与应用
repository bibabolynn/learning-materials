消息中间件 metamorphosis
  适用于大吞吐量、顺序消息、消息广播和日志数据传输等分布式应用场景，基于pull，zookeeper实现负载均衡和offset的存储
  生产者负载均衡：生产者会获取到已经配置好的topic对应的broker和分区列表，生产者会维护一个分区列表，发消息时，选择一台broker上的一个分区来发消息，
              问题：因为从故障到生产者感知这个变化有一定的延迟，所以可能在一瞬间会有部分的消息发送失败
  消费者负载均衡，为单个分组内的消费者集群的负载均衡
    消费者数和topic分区数一致，则一一对应
    消费者数大于topic分区数，多出来的不参与消费
    消费者数小于分区数，则有部分消费者需要承担额外的消费任务，每个分区至多同时允许被一个消费者消费
    
    
    
Dubbo
  核心部分：
  远程通信：提供对多种基于长连接的NIO框架抽象封装，包括多线程模型、序列化以及“请求-响应”模式的信息交换方式
  集群容错：提供基于接口方法的远程过程透明调用，包括对多协议的支持，以及对软负载均衡、失败容错、地址路由和动态配置等集群特性的支持
  自动发现：提供基于注册中心的目录服务，使服务消费方能动态地查找服务提供方，使地址透明，使服务提供方可以平滑的增加或减少机器。
  基于zookeeper实现服务注册中心，用于服务的注册和订阅。
  基于zookeeper实现的注册中心节点结构示意图见issues（搜索 dubbo 和 zookeeper）
  
Canal 基于MySQL Binlog 的增量订阅和消费组件
   工作原理：模拟 MySQL slave的交互协议，将自己伪装为一个MySQL的slave机器，然后不断的向master发送dump请求，
   master收到dump请求后就会将相应的binary log 推送给该slave，
   canal收到binary log 后就可以进行二次消费了
   
   主备切换
   为了减少canal server的dump请求对于MySQL master所带来的性能影响，要求不同的canal server 上的instance在同一时刻只能有一个处于running状态
   依赖zookeeper实现主备切换机制：
     每个canal server 在启动canal instance的时候想zookeeper创建一个相同的节点，创建成功了，则把机器信息写入该节点，
     然后启动canal instance，不成功就standby，并监听该节点
     解决“假死”：standby 的canal server在收到running节点释放的通知后，会延迟一段时间抢占running节点，而原running节点不需要等待延迟。延迟默认5s
   canal client 从zookeeper 找到running的机器，监听running节点
   数据消费节点的记录：防止canal client的重启或其他变化导致数据消费的重复性和顺序错乱
    canal server 会记录最后一次消费成功的binary log 位点
    
Otter 分布式数据库同步系统  致力于异地双A机房的数据库准实时数据同步
  zookeeper负责分布式协调，需要面向全球机房服务，保证读写数据的一致性
  zookeerper在3.3.0新增了observer模式，该角色提供只读服务，不参与事务请求的投票，
  如果在美国、杭州、青岛各有一组集群，杭州可以部署leader/follower，处理所有的事务请求，其他部署observer模式，处理当地的所有非事务请求，减少网络延迟的影响
  当地的事务请求转发给杭州机房，事务请求的都在一个机房内部完成也会大大提升集群对事务请求的处理能力
  
JStorm 实时计算引擎
是一个类似于map reduce 的分布式任务调度系统，用户按照指定的接口编写一个任务程序，然后将这个任务程序提交给JStorm系统，JStorm会负责7X24小时运行并调度该任务
广泛应用于日志分析、消息转化和统计分析器等一系列无状态的实时计算系统
依赖zookeeper实现诸如同步心跳、同步任务配置和调度器选举等
核心部分：
  Nimbus是任务的中央调度器
  supervisor是worker的代理角色，负责管理worker的生命周期
  worker是task的容器
  task对应每一个任务的真正执行体
  zookeeper是整个系统中的协调者
  
同步心跳：
  # worker想supervisor汇报心跳
  # supervisor向Nimbus汇报心跳
  # task向Nimbus汇报心跳
  后两种是通过zookeeper来实现的
  supervisor每隔10s就会将自己拥有的资源数同步到zookeeper的/supervisors节点上，Nimbus可以通过查询这些节点来检测有哪些机器是活着的
  task每隔10s就会将自己的心跳和运行状态同步到zookeeper的/tasks节点上，Nimbus一旦检查到某个task心跳超时，则会对该task执行reassign动作
  
同步任务配置：
  提交任务：
  同步Topology
  
  


  



  
  
  

  
  
